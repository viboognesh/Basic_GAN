{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pdb\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn \n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation Function\n",
    "def show(tensor, ch=1, size=(28,28), num=16):\n",
    "    #tensor: 128 x 784\n",
    "    data = tensor.detach().cpu().view(-1,ch,*size) \n",
    "    grid = make_grid(data[:num], nrow=4).permute(1,2,0)\n",
    "    plt.imshow(grid)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup of the main parameters and hyperparameters\n",
    "epochs = 500\n",
    "current_step = 0\n",
    "info_step = 1875\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "\n",
    "z_dimension = 64\n",
    "lr = 0.0001\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "batch_size = 125\n",
    "device = 'cuda' \n",
    "\n",
    "dataloader = DataLoader(MNIST(\"./data\",download=True, transform=transforms.ToTensor()),shuffle=True,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare our models\n",
    "\n",
    "# Generator\n",
    "def generatorBlock(inp, out):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features=inp, out_features=out),\n",
    "        nn.BatchNorm1d(num_features=out),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dimension=64, i_dimension=784, h_dimension=128):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generatorBlock(z_dimension, h_dimension), #64 -> 128\n",
    "            generatorBlock(h_dimension, h_dimension*2), #128 -> 256\n",
    "            generatorBlock(h_dimension*2, h_dimension*4), #256 -> 512\n",
    "            generatorBlock(h_dimension*4, h_dimension*8), #512 -> 1024\n",
    "            nn.Linear(h_dimension*8, i_dimension), # 1024 -> 784\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def gen_noise(number, z_dimension):\n",
    "    return torch.randn(number, z_dimension).to(device)\n",
    "\n",
    "# Discriminator\n",
    "def discriminatorBlock(inp, out):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features=inp, out_features=out),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, i_dimension=784, h_dimension=256):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            discriminatorBlock(i_dimension, h_dimension*4), #784 * 1024\n",
    "            discriminatorBlock(h_dimension*4, h_dimension*2),\n",
    "            discriminatorBlock(h_dimension*2, h_dimension),\n",
    "            nn.Linear(h_dimension, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, image):\n",
    "        return self.disc(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(z_dimension=z_dimension).to(device=device)\n",
    "gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "discriminator = Discriminator().to(device=device)\n",
    "disc_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "print(x.shape, y.shape)\n",
    "print(y[:10])\n",
    "\n",
    "noise = gen_noise(batch_size, z_dimension=z_dimension)\n",
    "fake = generator(noise)\n",
    "show(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the loss\n",
    "\n",
    "# Generator Loss\n",
    "def calculate_gen_loss(loss_fn, generator, discriminator, number, z_dimension):\n",
    "    noise = gen_noise(number=number, z_dimension=z_dimension)\n",
    "    fake = generator(noise)\n",
    "    pred = discriminator(fake)\n",
    "    target = torch.ones_like(pred)\n",
    "    gen_loss = loss_fn(pred,target)\n",
    "    \n",
    "    return gen_loss\n",
    "\n",
    "def calculate_disc_loss(loss_fn, generator, discriminator, number, real, z_dimension):\n",
    "    noise = gen_noise(number=number, z_dimension=z_dimension)\n",
    "    fake = generator(noise)\n",
    "    discriminator_fake = discriminator(fake.detach())\n",
    "    disc_fake_targets = torch.zeros_like(discriminator_fake)\n",
    "    disc_fake_loss = loss_fn(discriminator_fake, disc_fake_targets)\n",
    "\n",
    "    disc_real = discriminator(real)\n",
    "    disc_real_targets = torch.ones_like(disc_real)\n",
    "    disc_real_loss = loss_fn(disc_real, disc_real_targets)\n",
    "\n",
    "    disc_loss = (disc_fake_loss + disc_real_loss)/2\n",
    "\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        ## Discriminator\n",
    "        disc_optimizer.zero_grad()\n",
    "        \n",
    "        current_batch_size = len(real) #real: 128\n",
    "        real = real.view(current_batch_size, -1)\n",
    "        real = real.to(device)\n",
    "        \n",
    "        discriminator_loss = calculate_disc_loss(loss_fn=loss_fn, generator=generator, discriminator=discriminator, number=current_batch_size, real=real, z_dimension=z_dimension)\n",
    "        \n",
    "        discriminator_loss.backward(retain_graph=True)\n",
    "        disc_optimizer.step()\n",
    "        \n",
    "        #Generator\n",
    "        gen_optimizer.zero_grad()\n",
    "        gen_loss = calculate_gen_loss(loss_fn=loss_fn, generator=generator, discriminator=discriminator, number=current_batch_size, z_dimension=z_dimension)\n",
    "        gen_loss.backward(retain_graph=True)\n",
    "        gen_optimizer.step()\n",
    "        \n",
    "        #Visualisation and stats\n",
    "        mean_discriminator_loss += discriminator_loss.item()/info_step\n",
    "        mean_generator_loss += gen_loss.item()/info_step\n",
    "        \n",
    "        if current_step % info_step == 0 and current_step > 0:\n",
    "            fake_noise = gen_noise(current_batch_size, z_dimension=z_dimension)\n",
    "            fake = generator(fake_noise)\n",
    "            show(fake)\n",
    "            show(real)\n",
    "            print(f'{epoch}: step {current_step}, generator loss:{mean_generator_loss}, discriminator loss:{mean_discriminator_loss}')\n",
    "            mean_discriminator_loss, mean_generator_loss = 0, 0\n",
    "            \n",
    "        current_step+=1\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_noise = gen_noise(128, z_dimension=z_dimension)\n",
    "fake = generator(fake_noise)\n",
    "show(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
